"""
word2vec (google)
fasttext (facebook)
"""

# import library
import matplotlib.pyplot as plt

from sklearn.decomposition import PCA # Principle component analysis: dimension reduction (BOYUT Ä°NDÄ°RGEMESÄ°)

from gensim.models import Word2Vec, FastText
from gensim.utils import simple_preprocess

# ornek veri seti olustur
sentences = [
    # ğŸ¾ Hayvanlar
    "KÃ¶pekler sadÄ±k hayvanlardÄ±r.",
    "Kediler evde yalnÄ±z kalmaktan hoÅŸlanmaz.",
    "PapaÄŸanlar konuÅŸmayÄ± Ã¶ÄŸrenebilir.",
    "Atlar hÄ±zlÄ± koÅŸabilir.",
    "BalÄ±klar suda yaÅŸar.",
    "KÃ¶pek balÄ±klarÄ± tehlikeli olabilir.",
    "KuÅŸlar sabahlarÄ± Ã¶ter.",
    "Kedi sessizce yÃ¼rÃ¼r.",
    "KÃ¶pekler sahiplerini korur.",
    "KÃ¶pek kulÃ¼besinde uyur.",

    # ğŸš— UlaÅŸÄ±m
    "Arabalar yollarda hÄ±zla gider.",
    "OtobÃ¼s durakta bekler.",
    "UÃ§aklar havalanmadan Ã¶nce piste gelir.",
    "Trenler raylarda hareket eder.",
    "Bisiklet Ã§evre dostudur.",
    "Gemi limana yanaÅŸtÄ±.",
    "Metro kalabalÄ±k olabilir.",
    "Taksi ÅŸehir iÃ§inde yaygÄ±ndÄ±r.",
    "UÃ§akla seyahat hÄ±zlÄ±dÄ±r.",
    "OtobÃ¼s yolcularÄ±nÄ± aldÄ±.",

    # ğŸ½ï¸ Yemek
    "Elma saÄŸlÄ±klÄ± bir meyvedir.",
    "Pizza Ã§ok lezzetliydi.",
    "Ã‡orba sÄ±cak servis edilir.",
    "Kahve sabahlarÄ± iÃ§ilir.",
    "Tavuk fÄ±rÄ±nda piÅŸti.",
    "Pilav beyaz pirinÃ§ten yapÄ±lÄ±r.",
    "Karpuz yazÄ±n serinletir.",
    "Salata tazeydi.",
    "Bal tatlÄ±dÄ±r.",
    "Pasta doÄŸum gÃ¼nÃ¼nde kesilir."
]


tokenized_sentences = [simple_preprocess(sentece) for sentece in sentences]

# word2vec
word2_vec_model = Word2Vec(sentences= tokenized_sentences,vector_size=50, window=5,min_count=1,sg=0)

# fasttext
fasttext_model = FastText(sentences= tokenized_sentences,vector_size=50, window=5,min_count=1,sg=0)

# gorsellestirme: PCA

def plot_word_embedding(model, title):
    
    word_vectors = model.wv
    
    words = list(word_vectors.index_to_key)[:1000]
    vectors = [word_vectors[word] for word in words]
    
    # PCA
    pca = PCA(n_components=3)
    reduced_vectors = pca.fit_transform(vectors)
    
    # 3d gorsellestirme
    fig = plt.figure(figsize=(8,6))
    ax = fig.add_subplot(111, projection = "3d")

    # vektorleri ciz
    ax.scatter(reduced_vectors[:, 0], reduced_vectors[:, 1], reduced_vectors[:, 2])
    
    # kelimeleri etiketle
    for i, word in enumerate(words):
        ax.text(reduced_vectors[i, 0], reduced_vectors[i, 1], reduced_vectors[i, 2], word, fontsize=10)


    ax.set_title(title)    
    ax.set_xlabel("Component 1")
    ax.set_ylabel("Component 2")
    ax.set_zlabel("Component 3")
    plt.show()
    
plot_word_embedding(word2_vec_model, "Word2Vec")
plot_word_embedding(fasttext_model, "Fasttext")


